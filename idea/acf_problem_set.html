<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Time Series Problem Set: Autocorrelation Function (ACF)</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            padding: 40px;
        }

        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
            border-bottom: 4px solid #667eea;
            padding-bottom: 20px;
        }

        .subtitle {
            text-align: center;
            color: #7f8c8d;
            margin-bottom: 30px;
            font-size: 1.1em;
        }

        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            padding: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 8px;
            font-size: 1.8em;
        }

        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.4em;
            border-left: 5px solid #667eea;
            padding-left: 15px;
        }

        .problem {
            background: #f8f9fa;
            border-left: 4px solid #3498db;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .solution {
            background: #e8f5e9;
            border-left: 4px solid #4caf50;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .problem h4, .solution h4 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 1.2em;
        }

        .illustration-badge {
            display: inline-block;
            background: #ff9800;
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: bold;
            margin-left: 10px;
        }

        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #e83e8c;
            font-size: 0.9em;
        }

        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 15px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }

        pre code {
            background: transparent;
            color: #f8f8f2;
            padding: 0;
        }

        ul, ol {
            margin-left: 25px;
            margin-top: 10px;
        }

        li {
            margin: 8px 0;
        }

        .math {
            font-family: 'Times New Roman', serif;
            font-style: italic;
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
        }

        img {
            max-width: 100%;
            height: auto;
            margin: 15px 0;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        .summary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-top: 40px;
        }

        .summary h2 {
            background: transparent;
            border: none;
            padding: 0;
            margin-bottom: 20px;
        }

        .summary ul {
            list-style: none;
            margin-left: 0;
        }

        .summary li {
            padding: 10px;
            margin: 5px 0;
            background: rgba(255,255,255,0.1);
            border-radius: 5px;
        }

        .exercise-type {
            background: #fff;
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 25px;
            margin: 25px 0;
        }

        .note {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }

        .note strong {
            color: #856404;
        }

        @media print {
            body {
                background: white;
                padding: 0;
            }
            .container {
                box-shadow: none;
                padding: 20px;
            }
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            h1 {
                font-size: 1.8em;
            }
            h2 {
                font-size: 1.4em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Time Series Problem Set: Autocorrelation Function (ACF)</h1>
        <p class="subtitle">Complete Problem Set with Solutions - Undergraduate Level</p>

        <div class="exercise-type">
            <h2>Exercise Type 1: Numerical ACF Calculation</h2>
            
            <div class="problem">
                <h4>Problem 1.1</h4>
                <p>Given the time series: <span class="math">x = [2, 4, 6, 8, 10]</span></p>
                <img src="figures/problem1_1_timeseries.png" alt="Time Series Plot for Problem 1.1">
                <p>Compute:</p>
                <ol>
                    <li>The sample mean <span class="math">x̄</span></li>
                    <li>The sample variance <span class="math">s²</span></li>
                    <li>The autocovariance <span class="math">γ(k)</span> for lags <span class="math">k = 0, 1, 2</span></li>
                    <li>The autocorrelation <span class="math">ρ(k)</span> for lags <span class="math">k = 0, 1, 2</span></li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 1.1</h4>
                <p><strong>1. Sample Mean:</strong></p>
                <p class="math">x̄ = (2 + 4 + 6 + 8 + 10) / 5 = 30 / 5 = 6</p>
                
                <p><strong>2. Sample Variance:</strong></p>
                <p>Deviations from mean: [-4, -2, 0, 2, 4]</p>
                <p class="math">s² = [(-4)² + (-2)² + 0² + 2² + 4²] / 4 = 40 / 4 = 10</p>
                
                <p><strong>3. Autocovariance:</strong></p>
                <p>For lag k = 0: γ(0) = 8</p>
                <p>For lag k = 1: γ(1) = 3.2</p>
                <p>For lag k = 2: γ(2) = -0.8</p>
                
                <p><strong>4. Autocorrelation:</strong></p>
                <p>ρ(0) = 1.0, ρ(1) = 0.4, ρ(2) = -0.1</p>
            </div>

            <div class="problem">
                <h4>Problem 1.2</h4>
                <p>Given the time series: <span class="math">x = [5, 5, 5, 5, 5]</span></p>
                <p>Compute the autocovariance and autocorrelation. What happens when all values are identical?</p>
            </div>

            <div class="solution">
                <h4>Solution 1.2</h4>
                <p><strong>Sample Mean:</strong> x̄ = 5</p>
                <p><strong>Sample Variance:</strong> s² = 0 (all deviations are zero)</p>
                <p><strong>Autocovariance:</strong> γ(0) = 0, γ(k) = 0 for all k > 0</p>
                <p><strong>Autocorrelation:</strong> <strong>UNDEFINED</strong> - cannot divide by zero when γ(0) = 0</p>
                <div class="note">
                    <strong>Interpretation:</strong> A constant time series has no variability. The ACF cannot be computed because there is no variation to measure correlation against. In practice, such series are considered degenerate and ACF analysis is not meaningful.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 1.3</h4>
                <p>Given the time series: <span class="math">x = [10, 8, 6, 4, 2]</span></p>
                <img src="figures/problem1_3_timeseries.png" alt="Time Series Plot for Problem 1.3">
                <p>Compute the autocovariance <span class="math">γ(k)</span> and autocorrelation <span class="math">ρ(k)</span> for lags <span class="math">k = 0, 1, 2</span>.</p>
            </div>

            <div class="solution">
                <h4>Solution 1.3</h4>
                <p><strong>Sample Mean:</strong> x̄ = 6</p>
                <p><strong>Sample Variance:</strong> s² = 10</p>
                <p><strong>Autocovariance:</strong> γ(0) = 8, γ(1) = 3.2, γ(2) = -0.8</p>
                <p><strong>Autocorrelation:</strong> ρ(0) = 1.0, ρ(1) = 0.4, ρ(2) = -0.1</p>
                <div class="note">
                    <strong>Note:</strong> This series has the same ACF as Problem 1.1 because both are linear trends with the same variance structure.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 1.4</h4>
                <p>Given the time series: <span class="math">x = [3, 7, 3, 7, 3]</span></p>
                <img src="figures/problem1_4_timeseries.png" alt="Time Series Plot for Problem 1.4">
                <p>Compute the autocovariance and autocorrelation for lags <span class="math">k = 0, 1, 2, 3</span>.</p>
            </div>

            <div class="solution">
                <h4>Solution 1.4</h4>
                <p><strong>Sample Mean:</strong> x̄ = 4.6</p>
                <p><strong>Sample Variance:</strong> s² = 4.8</p>
                <p><strong>Autocovariance:</strong> γ(0) = 3.84, γ(1) = -3.072, γ(2) = 2.176, γ(3) = -1.536</p>
                <p><strong>Autocorrelation:</strong> ρ(0) = 1.0, ρ(1) = -0.8, ρ(2) = 0.5667, ρ(3) = -0.4</p>
                <div class="note">
                    <strong>Interpretation:</strong> The alternating pattern creates negative autocorrelation at odd lags and positive at even lags.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 1.5</h4>
                <p>Given the time series: <span class="math">x = [12, 15, 18, 12, 15, 18, 12]</span></p>
                <img src="figures/problem1_5_timeseries.png" alt="Time Series Plot for Problem 1.5">
                <p>Compute the autocovariance and autocorrelation for lags <span class="math">k = 0, 1, 2, 3</span>.</p>
            </div>

            <div class="solution">
                <h4>Solution 1.5</h4>
                <p><strong>Sample Mean:</strong> x̄ ≈ 14.571</p>
                <p><strong>Sample Variance:</strong> s² ≈ 7.286</p>
                <p><strong>Autocovariance:</strong> γ(0) ≈ 6.245, γ(1) ≈ -2.554, γ(2) ≈ -2.554, γ(3) ≈ 5.298</p>
                <p><strong>Autocorrelation:</strong> ρ(0) = 1.0, ρ(1) ≈ -0.409, ρ(2) ≈ -0.409, ρ(3) ≈ 0.848</p>
                <div class="note">
                    <strong>Interpretation:</strong> The period-3 pattern shows strong positive autocorrelation at lag 3 (the period length).
                </div>
            </div>
        </div>

        <div class="exercise-type">
            <h2>Exercise Type 2: Effect of Mean Removal</h2>
            
            <div class="problem">
                <h4>Problem 2.1</h4>
                <p>Given the time series: <span class="math">x = [5, 7, 9, 11, 13]</span></p>
                <img src="figures/problem2_1_timeseries.png" alt="Time Series Plot for Problem 2.1">
                <ol>
                    <li>Compute the autocovariance <strong>without</strong> removing the mean.</li>
                    <li>Compute the autocovariance <strong>with</strong> mean removal.</li>
                    <li>Compare the results and explain why mean removal is necessary.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 2.1</h4>
                <p><strong>Part 1: Without Mean Removal</strong></p>
                <p>γ(0) = 89, γ(1) = 68, ρ(1) = 68/89 = 0.764</p>
                
                <p><strong>Part 2: With Mean Removal</strong></p>
                <p>γ(0) = 8, γ(1) = 3.2, ρ(1) = 3.2/8 = 0.4</p>
                
                <p><strong>Part 3: Comparison</strong></p>
                <div class="note">
                    <strong>Why mean removal is necessary:</strong> When we don't remove the mean, the autocovariance captures both the true correlation structure and the spurious correlation introduced by the non-zero mean. The large mean dominates the calculation, making the series appear more correlated than it actually is. Mean removal isolates the true correlation structure.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 2.2</h4>
                <p>Given the time series: <span class="math">x = [100, 102, 104, 106, 108]</span></p>
                <ol>
                    <li>Compute autocorrelation at lag 1 <strong>without</strong> mean removal.</li>
                    <li>Compute autocorrelation at lag 1 <strong>with</strong> mean removal.</li>
                    <li>Explain the difference.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 2.2</h4>
                <p><strong>Without mean removal:</strong> ρ(1) ≈ 0.799</p>
                <p><strong>With mean removal:</strong> ρ(1) = 0.4</p>
                <div class="note">
                    <strong>Explanation:</strong> The autocorrelation without mean removal is much higher because the large mean value creates artificial correlation. After mean removal, we see the actual correlation between deviations is only 0.4.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 2.3</h4>
                <p>Given the time series: <span class="math">x = [20, 20, 20, 25, 25, 25]</span></p>
                <img src="figures/problem2_3_timeseries.png" alt="Time Series Plot for Problem 2.3">
                <p>Compare the autocorrelation at lag 1 computed with and without mean removal. What does this tell you about the series?</p>
            </div>

            <div class="solution">
                <h4>Solution 2.3</h4>
                <p><strong>Without mean removal:</strong> ρ(1) ≈ 0.829</p>
                <p><strong>With mean removal:</strong> ρ(1) = 0.5</p>
                <div class="note">
                    <strong>Interpretation:</strong> The series has a step change. Without mean removal, autocorrelation is inflated. After mean removal, we see the correlation is 0.5, reflecting the step structure.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 2.4</h4>
                <p>Given the time series: <span class="math">x = [1, 3, 5, 1, 3, 5]</span></p>
                <p>Compute autocorrelation at lag 2 with and without mean removal. Explain why the results differ.</p>
            </div>

            <div class="solution">
                <h4>Solution 2.4</h4>
                <p><strong>Without mean removal:</strong> ρ(2) ≈ 0.4 (positive)</p>
                <p><strong>With mean removal:</strong> ρ(2) = -0.5 (negative)</p>
                <div class="note">
                    <strong>Explanation:</strong> Mean removal reveals the true correlation structure. Without it, the mean dominates and masks the underlying pattern. The series has period 3, so at lag 2, we're comparing out-of-phase positions, creating negative correlation.
                </div>
            </div>

            <div class="problem">
                <h4>Problem 2.5</h4>
                <p>Given the time series: <span class="math">x = [10, 12, 14, 10, 12, 14, 10]</span></p>
                <img src="figures/problem2_5_timeseries.png" alt="Time Series Plot for Problem 2.5">
                <ol>
                    <li>Compute autocorrelation at lag 3 with and without mean removal.</li>
                    <li>Explain which method gives the correct interpretation of the series' periodic structure.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 2.5</h4>
                <p><strong>Without mean removal:</strong> ρ(3) ≈ 0.551</p>
                <p><strong>With mean removal:</strong> ρ(3) ≈ 0.729</p>
                <div class="note">
                    <strong>Interpretation:</strong> The method with mean removal gives the correct interpretation. The series has period 3, and at lag 3 we should see strong positive correlation since we're comparing values at the same phase. The autocorrelation of 0.729 correctly identifies the strong periodic pattern.
                </div>
            </div>
        </div>

        <div class="exercise-type">
            <h2>Exercise Type 3: Interpreting ACF Patterns</h2>
            
            <div class="problem">
                <h4>Problem 3.1</h4>
                <p>A time series has an ACF plot where <span class="math">ρ(0) = 1</span> and <span class="math">ρ(k) ≈ 0</span> for all <span class="math">k > 0</span>, with values randomly scattered around zero within the confidence bands.</p>
                <img src="figures/problem3_1_timeseries.png" alt="Time Series Plot for Problem 3.1">
                <ol>
                    <li>What type of process does this indicate?</li>
                    <li>What are the characteristics of such a process?</li>
                    <li>Generate a synthetic time series with this ACF pattern and plot both the series and its ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 3.1</h4>
                <p><strong>1. Process Type:</strong> This indicates a <strong>white noise</strong> process.</p>
                <p><strong>2. Characteristics:</strong></p>
                <ul>
                    <li>No serial correlation (uncorrelated observations)</li>
                    <li>Constant mean and variance (stationary)</li>
                    <li>No predictable pattern</li>
                    <li>Each observation is independent of previous observations</li>
                    <li>Used as a baseline for model diagnostics</li>
                </ul>
                <p><strong>3. Python Code:</strong></p>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from statsmodels.graphics.tsaplots import plot_acf

# Set random seed for reproducibility
np.random.seed(42)

# Generate white noise time series
n = 200
white_noise = np.random.normal(loc=0, scale=1, size=n)

# Create time index
time = np.arange(n)

# Plot the time series
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(time, white_noise, linewidth=0.8, color='steelblue')
plt.title('White Noise Time Series', fontsize=14, fontweight='bold')
plt.xlabel('Time', fontsize=12)
plt.ylabel('Value', fontsize=12)
plt.grid(True, alpha=0.3)

# Compute and plot ACF
plt.subplot(1, 2, 2)
plot_acf(white_noise, lags=40, alpha=0.05, ax=plt.gca())
plt.title('ACF Plot: White Noise', fontsize=14, fontweight='bold')
plt.xlabel('Lag', fontsize=12)
plt.ylabel('Autocorrelation', fontsize=12)
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()</code></pre>
            </div>

            <div class="problem">
                <h4>Problem 3.2</h4>
                <p>A time series has an ACF plot showing <span class="math">ρ(k)</span> that decays very slowly, remaining positive and significant even at large lags (e.g., <span class="math">ρ(20) > 0.5</span>).</p>
                <img src="figures/problem3_2_timeseries.png" alt="Time Series Plot for Problem 3.2">
                <ol>
                    <li>What does this pattern indicate?</li>
                    <li>What type of non-stationarity is likely present?</li>
                    <li>Generate a synthetic time series with this ACF pattern and plot both the series and its ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 3.2</h4>
                <p><strong>1. Pattern Indication:</strong> This indicates a <strong>trend</strong> or <strong>non-stationary</strong> process. The slow decay suggests long memory, typically due to a deterministic or stochastic trend.</p>
                <p><strong>2. Non-stationarity Type:</strong> Deterministic trend, random walk, or unit root process.</p>
                <p><strong>3. Python Code:</strong></p>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from statsmodels.graphics.tsaplots import plot_acf

# Generate time series with trend
n = 200
time = np.arange(n)

# Option 1: Deterministic linear trend + noise
trend = 0.05 * time
noise = np.random.normal(0, 1, n)
trend_series = trend + noise

# Option 2: Random walk (stochastic trend)
random_walk = np.cumsum(np.random.normal(0, 1, n))

# Plot both series and their ACFs
# (Full code in markdown file)</code></pre>
            </div>

            <div class="problem">
                <h4>Problem 3.3</h4>
                <p>A time series has an ACF plot showing oscillatory (sinusoidal) behavior, with autocorrelations alternating between positive and negative values in a periodic pattern.</p>
                <img src="figures/problem3_3_timeseries.png" alt="Time Series Plot for Problem 3.3">
                <ol>
                    <li>What does this pattern indicate?</li>
                    <li>What type of seasonality or cyclical behavior is present?</li>
                    <li>Generate a synthetic time series with this ACF pattern and plot both the series and its ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 3.3</h4>
                <p><strong>1. Pattern Indication:</strong> This indicates <strong>seasonality</strong> or <strong>cyclical behavior</strong>.</p>
                <p><strong>2. Seasonality Type:</strong> Deterministic seasonality, cyclical component, or sinusoidal pattern.</p>
                <p><strong>3. Python Code:</strong></p>
                <pre><code>import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import acf
from statsmodels.graphics.tsaplots import plot_acf

# Generate time series with seasonality
n = 200
time = np.arange(n)

# Create seasonal component (period = 12)
seasonal_period = 12
seasonal_component = 5 * np.sin(2 * np.pi * time / seasonal_period)

# Add trend and noise
trend = 0.02 * time
noise = np.random.normal(0, 0.5, n)
seasonal_series = trend + seasonal_component + noise

# Plot and compute ACF
# (Full code in markdown file)</code></pre>
            </div>

            <div class="problem">
                <h4>Problem 3.4</h4>
                <p>A time series has an ACF plot where <span class="math">ρ(k)</span> shows a sharp cutoff after lag <span class="math">q = 2</span>, with <span class="math">ρ(1)</span> and <span class="math">ρ(2)</span> being significant, but <span class="math">ρ(k) ≈ 0</span> for all <span class="math">k > 2</span>.</p>
                <img src="figures/problem3_4_timeseries.png" alt="Time Series Plot for Problem 3.4">
                <ol>
                    <li>What type of process does this suggest?</li>
                    <li>What is the likely model order?</li>
                    <li>Generate a synthetic time series with this ACF pattern and plot both the series and its ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 3.4</h4>
                <p><strong>1. Process Type:</strong> This suggests a <strong>Moving Average (MA) process of order 2</strong>, specifically <strong>MA(2)</strong>.</p>
                <p><strong>2. Model Order:</strong> MA(2) or ARIMA(0,0,2)</p>
                <p><strong>3. Python Code:</strong></p>
                <pre><code>from statsmodels.tsa.arima_process import ArmaProcess

# Generate MA(2) process
ma_coeffs = np.array([1, 0.5, 0.3])  # [1, θ1, θ2]
ar_coeffs = np.array([1])

arma_process = ArmaProcess(ar_coeffs, ma_coeffs)
ma2_series = arma_process.generate_sample(nsample=200)

# Plot and compute ACF
# (Full code in markdown file)</code></pre>
            </div>

            <div class="problem">
                <h4>Problem 3.5</h4>
                <p>A time series has an ACF plot showing exponential decay: <span class="math">ρ(k)</span> starts high and decays gradually, remaining positive but decreasing, with no sharp cutoff.</p>
                <img src="figures/problem3_5_timeseries.png" alt="Time Series Plot for Problem 3.5">
                <ol>
                    <li>What type of process does this indicate?</li>
                    <li>How does this differ from the MA process pattern?</li>
                    <li>Generate a synthetic time series with this ACF pattern and plot both the series and its ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 3.5</h4>
                <p><strong>1. Process Type:</strong> This indicates an <strong>Autoregressive (AR) process</strong>.</p>
                <p><strong>2. Difference from MA:</strong> AR processes show exponential decay (gradual decline), while MA processes cut off sharply after lag q.</p>
                <p><strong>3. Python Code:</strong></p>
                <pre><code>from statsmodels.tsa.arima_process import ArmaProcess

# Generate AR(1) process
ar_coeffs = np.array([1, -0.7])  # [1, -φ1] for AR(1)
ma_coeffs = np.array([1])

arma_process = ArmaProcess(ar_coeffs, ma_coeffs)
ar1_series = arma_process.generate_sample(nsample=200)

# Plot and compute ACF
# (Full code in markdown file)</code></pre>
            </div>
        </div>

        <div class="exercise-type">
            <h2>Exercise Type 4: Physiological Time-Series Interpretation</h2>
            
            <div class="problem">
                <h4>Problem 4.1</h4>
                <p>Consider a heart rate time series where the ACF shows:</p>
                <ul>
                    <li>Strong positive autocorrelation at lag 1 (<span class="math">ρ(1) ≈ 0.8</span>)</li>
                    <li>Rapid decay to near zero by lag 5</li>
                    <li>No significant periodic patterns</li>
                </ul>
                <img src="figures/problem4_1_timeseries.png" alt="Time Series Plot for Problem 4.1">
                <ol>
                    <li>What does this tell you about the memory length of the process?</li>
                    <li>What AR/MA/ARIMA model order would be appropriate?</li>
                    <li>Would deep learning be necessary for forecasting?</li>
                    <li>Generate a synthetic heart rate time series with these characteristics and plot the series and ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 4.1</h4>
                <p><strong>1. Memory Length:</strong> The process has <strong>short memory</strong> (approximately 5 time steps).</p>
                <p><strong>2. Model Order:</strong> AR(1) or ARIMA(1,0,0) would be appropriate.</p>
                <p><strong>3. Deep Learning:</strong> <strong>No, deep learning is not necessary.</strong> Traditional AR/ARIMA models are sufficient because the process has short memory and simple ACF pattern.</p>
                <p><strong>4. Python Code:</strong> (See markdown file for complete code)</p>
            </div>

            <div class="problem">
                <h4>Problem 4.2</h4>
                <p>Consider a blood pressure time series where the ACF shows:</p>
                <ul>
                    <li>Very slow decay, remaining above 0.5 even at lag 20</li>
                    <li>No clear periodic pattern</li>
                    <li>Gradual decrease rather than sharp cutoff</li>
                </ul>
                <img src="figures/problem4_2_timeseries.png" alt="Time Series Plot for Problem 4.2">
                <ol>
                    <li>What does this indicate about the process?</li>
                    <li>What preprocessing step might be necessary?</li>
                    <li>What model would be appropriate after preprocessing?</li>
                    <li>Generate a synthetic blood pressure time series and plot the series and ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 4.2</h4>
                <p><strong>1. Process Indication:</strong> This indicates a <strong>non-stationary process</strong>, likely a random walk or unit root process.</p>
                <p><strong>2. Preprocessing:</strong> <strong>First-order differencing</strong> is necessary to make the series stationary.</p>
                <p><strong>3. Model:</strong> After differencing, ARIMA(1,1,0) would be appropriate for the original series.</p>
                <p><strong>4. Python Code:</strong> (See markdown file for complete code)</p>
            </div>

            <div class="problem">
                <h4>Problem 4.3</h4>
                <p>Consider an EEG-like signal where the ACF shows:</p>
                <ul>
                    <li>Oscillatory pattern with period approximately 10 time steps</li>
                    <li>Significant autocorrelation at lags 10, 20, 30</li>
                    <li>Decay in amplitude of oscillations over time</li>
                </ul>
                <img src="figures/problem4_3_timeseries.png" alt="Time Series Plot for Problem 4.3">
                <ol>
                    <li>What does this indicate about the signal?</li>
                    <li>What type of seasonality is present?</li>
                    <li>Would a seasonal ARIMA model be appropriate?</li>
                    <li>Generate a synthetic EEG-like signal and plot the series and ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 4.3</h4>
                <p><strong>1. Signal Indication:</strong> The signal has a <strong>strong periodic/seasonal component</strong> with period 10.</p>
                <p><strong>2. Seasonality Type:</strong> <strong>Deterministic seasonality</strong> with period 10.</p>
                <p><strong>3. Seasonal ARIMA:</strong> Yes, a <strong>SARIMA model</strong> would be appropriate, e.g., SARIMA(1,0,1)(1,0,1)₁₀.</p>
                <p><strong>4. Python Code:</strong> (See markdown file for complete code)</p>
            </div>

            <div class="problem">
                <h4>Problem 4.4</h4>
                <p>Consider a respiratory rate time series where the ACF shows:</p>
                <ul>
                    <li>Sharp cutoff after lag 2</li>
                    <li><span class="math">ρ(1) ≈ 0.6</span>, <span class="math">ρ(2) ≈ 0.3</span></li>
                    <li><span class="math">ρ(k) ≈ 0</span> for <span class="math">k > 2</span></li>
                </ul>
                <img src="figures/problem4_4_timeseries.png" alt="Time Series Plot for Problem 4.4">
                <ol>
                    <li>What type of process does this indicate?</li>
                    <li>What is the memory length?</li>
                    <li>What model order would be appropriate?</li>
                    <li>Generate a synthetic respiratory rate time series and plot the series and ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 4.4</h4>
                <p><strong>1. Process Type:</strong> This indicates a <strong>Moving Average (MA) process of order 2</strong>, specifically <strong>MA(2)</strong>.</p>
                <p><strong>2. Memory Length:</strong> The memory extends only <strong>2 time steps</strong>.</p>
                <p><strong>3. Model Order:</strong> <strong>MA(2) or ARIMA(0,0,2)</strong> would be appropriate.</p>
                <p><strong>4. Python Code:</strong> (See markdown file for complete code)</p>
            </div>

            <div class="problem">
                <h4>Problem 4.5</h4>
                <p>Consider a body temperature time series where the ACF shows:</p>
                <ul>
                    <li>Exponential decay starting at <span class="math">ρ(1) ≈ 0.9</span></li>
                    <li>Gradual decrease: <span class="math">ρ(5) ≈ 0.5</span>, <span class="math">ρ(10) ≈ 0.2</span></li>
                    <li>All values positive, no oscillations</li>
                </ul>
                <img src="figures/problem4_5_timeseries.png" alt="Time Series Plot for Problem 4.5">
                <ol>
                    <li>What type of process does this indicate?</li>
                    <li>What is the approximate memory length?</li>
                    <li>Would deep learning provide significant advantages over traditional methods?</li>
                    <li>Generate a synthetic body temperature time series and plot the series and ACF.</li>
                </ol>
            </div>

            <div class="solution">
                <h4>Solution 4.5</h4>
                <p><strong>1. Process Type:</strong> This indicates an <strong>Autoregressive (AR) process</strong>, likely <strong>AR(1)</strong> with a high coefficient.</p>
                <p><strong>2. Memory Length:</strong> The "effective memory" might be around <strong>10-15 time steps</strong>.</p>
                <p><strong>3. Deep Learning:</strong> <strong>Probably not necessary</strong> for simple AR(1) processes, but might help if there are nonlinear relationships.</p>
                <p><strong>4. Python Code:</strong> (See markdown file for complete code)</p>
            </div>
        </div>

        <div class="summary">
            <h2>Summary</h2>
            <p>This problem set covers:</p>
            <ul>
                <li><strong>Numerical ACF Calculation:</strong> Manual computation of autocovariance and autocorrelation, including edge cases (constant series, zero variance).</li>
                <li><strong>Mean Removal Effect:</strong> Understanding why mean removal is essential for correct autocorrelation computation and avoiding spurious correlations.</li>
                <li><strong>ACF Pattern Interpretation:</strong> Identifying process types (white noise, trend, seasonality, AR, MA) from ACF plots with Python visualizations.</li>
                <li><strong>Physiological Time-Series:</strong> Applying ACF analysis to real-world biomedical signals, determining appropriate models, and assessing when advanced methods are needed.</li>
            </ul>
            <p style="margin-top: 20px;"><strong>All problems include complete solutions with mathematical derivations, Python code for illustrations, and pedagogical explanations suitable for undergraduate students.</strong></p>
        </div>
    </div>
</body>
</html>
